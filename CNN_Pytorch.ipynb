{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c1c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'D:\\Anaconda\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.empty_cache() \n",
    "# del model\n",
    "# del trainloader\n",
    "# del testloader\n",
    "print(torch.cuda.memory_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486d48fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomPerspective(p=0.5),\n",
    "     transforms.RandomRotation(degrees=(90, -90), fill=(0,))\n",
    "     transforms.ColorJitter(brightness=(0.5,1.5),contrast=(1),saturation=(0.5,1.5),hue=(-0.1,0.1)),\n",
    "     transforms.Resize((150,150)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='Geo_data/seg_train', transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='Geo_data/seg_test', transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89e7fdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 0 1 NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available(), torch.cuda.current_device(), torch.cuda.device_count(), torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a13fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635443f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_accuracy():\n",
    "    \n",
    "    correct_images = 0\n",
    "    total_images = 0\n",
    "    with torch.no_grad(): \n",
    "        for images,labels in testloader:\n",
    "            images, labels = images.to('cuda'),labels.to('cuda')\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_images += labels.size(0)\n",
    "            correct_images += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc = 100 * correct_images // total_images\n",
    "        return acc\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=6, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=1024, out_channels=2048, kernel_size=6, padding=1)\n",
    "\n",
    "        self.res1 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(64, 64, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.res2 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(128),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(128, 128, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(128))\n",
    "\n",
    "        self.res3 = nn.Sequential(nn.Conv2d(256, 256, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(256),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(256, 256, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(256))\n",
    "        \n",
    "        self.res4 = nn.Sequential(nn.Conv2d(512, 512, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(512, 512, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(512))\n",
    "        \n",
    "        self.res5= nn.Sequential(nn.Conv2d(1024, 1024, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(1024),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Conv2d(1024, 1024, kernel_size=3, padding = 1),\n",
    "                                  nn.BatchNorm2d(1024))\n",
    "        \n",
    "        \n",
    "        self.batchnorm2d_1 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm2d_2 = nn.BatchNorm2d(128)\n",
    "        self.batchnorm2d_3 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm2d_4 = nn.BatchNorm2d(512)\n",
    "        self.batchnorm2d_5 = nn.BatchNorm2d(1024)\n",
    "        self.batchnorm2d_6 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(8192, 120),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(120, 6))\n",
    "    def forward(self, xb):\n",
    "        x = F.relu(self.conv1(xb))\n",
    "        x = self.batchnorm2d_1(x)\n",
    "\n",
    "        x = F.relu(self.res1(x) + x)\n",
    "        x = F.relu(self.res1(x) + x)\n",
    "   \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.batchnorm2d_2(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.res2(x) + x)\n",
    "        x = F.relu(self.res2(x) + x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batchnorm2d_3(x)\n",
    "        \n",
    "        x = F.relu(self.res3(x) + x)\n",
    "        x = F.relu(self.res3(x) + x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batchnorm2d_4(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.res4(x) + x)\n",
    "        x = F.relu(self.res4(x) + x)\n",
    "\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.batchnorm2d_5(x)\n",
    "        x = self.pool(x)\n",
    "      \n",
    "        x = F.relu(self.res5(x) + x)\n",
    "        x = F.relu(self.res5(x) + x)\n",
    "\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.batchnorm2d_6(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def train_step(self, images, targets):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        predictions = self(images)\n",
    "        loss = F.cross_entropy(predictions, targets)\n",
    "        return loss\n",
    "\n",
    "    def validate_batch(self, images, targets):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        preds = self(images)\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "        acc = self.accuracy(preds, targets)\n",
    "        return {\"loss\": loss, \"acc\":acc}\n",
    "\n",
    "    def evaluate(self):\n",
    "        #generate output for every batch in the test data and evaluate the epoch\n",
    "\n",
    "        output = [self.validate_batch(images.to(device), targets.to(device)) for images, targets in testloader]\n",
    "        epoch_result = self.validate_epoch(output)\n",
    "\n",
    "        return epoch_result\n",
    "\n",
    "    def accuracy(self, outputs, targets):\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        acc = torch.tensor(torch.sum(preds == targets).item() / len(preds))\n",
    "        return acc\n",
    "\n",
    "    def validate_epoch(self, outputs):\n",
    "\n",
    "        batch_accs = [x[\"acc\"] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "\n",
    "        loss = [x[\"loss\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(loss).mean()\n",
    "\n",
    "        return {\"acc\": epoch_acc, \"loss\": epoch_loss}\n",
    "\n",
    "model = CNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1c6a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "max_lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=max_lr, weight_decay=1e-4, momentum = 0.9)\n",
    "\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=100, \n",
    "                                                steps_per_epoch=len(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62309052",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3aa459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on  NVIDIA GeForce GTX 1060 6GB\n",
      "Epoch [0]: loss: 1.2871226465414989, accuracy: 41%, time finished: 2022-04-08 13:20:23.558706\n",
      "Epoch [1]: loss: 0.9247674599001129, accuracy: 49%, time finished: 2022-04-08 13:48:16.514686\n",
      "Epoch [2]: loss: 0.7454270050736465, accuracy: 53%, time finished: 2022-04-08 14:16:04.880674\n",
      "Epoch [3]: loss: 0.6486629911739009, accuracy: 60%, time finished: 2022-04-08 14:43:20.631758\n",
      "Epoch [4]: loss: 0.5723570122575427, accuracy: 64%, time finished: 2022-04-08 15:10:54.699788\n",
      "Epoch [5]: loss: 0.5186041552898171, accuracy: 66%, time finished: 2022-04-08 15:38:35.073646\n",
      "Epoch [6]: loss: 0.48078528140377214, accuracy: 70%, time finished: 2022-04-08 16:07:48.163198\n",
      "Epoch [7]: loss: 0.451666129149452, accuracy: 71%, time finished: 2022-04-08 16:35:35.273995\n",
      "Epoch [8]: loss: 0.4165121330411844, accuracy: 73%, time finished: 2022-04-08 17:02:40.153434\n",
      "Epoch [9]: loss: 0.39189946768292083, accuracy: 74%, time finished: 2022-04-08 17:29:42.351420\n",
      "Epoch [10]: loss: 0.37733200356065766, accuracy: 74%, time finished: 2022-04-08 17:57:45.603029\n",
      "Epoch [11]: loss: 0.36194428186122835, accuracy: 74%, time finished: 2022-04-08 18:25:37.642882\n",
      "Epoch [12]: loss: 0.34520538654806077, accuracy: 75%, time finished: 2022-04-08 18:52:36.948846\n",
      "Epoch [13]: loss: 0.3289785238391136, accuracy: 77%, time finished: 2022-04-08 19:19:35.999641\n",
      "Epoch [14]: loss: 0.3132562607537694, accuracy: 76%, time finished: 2022-04-08 19:46:34.949217\n",
      "Epoch [15]: loss: 0.30451616861348185, accuracy: 77%, time finished: 2022-04-08 20:13:34.089843\n",
      "Epoch [16]: loss: 0.30208681119630715, accuracy: 80%, time finished: 2022-04-08 20:40:33.204572\n",
      "Epoch [17]: loss: 0.27457169304004775, accuracy: 79%, time finished: 2022-04-08 21:07:34.159617\n",
      "Epoch [18]: loss: 0.2712225868570875, accuracy: 81%, time finished: 2022-04-08 21:35:18.319163\n",
      "Epoch [19]: loss: 0.26364833281939665, accuracy: 79%, time finished: 2022-04-08 22:04:30.891299\n",
      "Epoch [20]: loss: 0.2606262870464942, accuracy: 77%, time finished: 2022-04-08 22:33:38.033742\n",
      "Epoch [21]: loss: 0.24724262505572664, accuracy: 79%, time finished: 2022-04-08 23:01:47.300115\n",
      "Epoch [22]: loss: 0.24224522958768016, accuracy: 80%, time finished: 2022-04-08 23:30:19.533591\n",
      "Epoch [23]: loss: 0.22846890870395986, accuracy: 81%, time finished: 2022-04-08 23:58:51.385299\n",
      "Epoch [24]: loss: 0.21725732483135543, accuracy: 79%, time finished: 2022-04-09 00:27:22.776349\n",
      "Epoch [25]: loss: 0.21199961898053604, accuracy: 79%, time finished: 2022-04-09 00:55:54.076598\n",
      "Epoch [26]: loss: 0.21013508096575723, accuracy: 81%, time finished: 2022-04-09 01:24:24.988882\n",
      "Epoch [27]: loss: 0.20714155351026275, accuracy: 81%, time finished: 2022-04-09 01:52:59.733753\n",
      "Epoch [28]: loss: 0.21306205214832202, accuracy: 81%, time finished: 2022-04-09 02:21:30.870522\n",
      "Epoch [29]: loss: 0.19321536893806066, accuracy: 81%, time finished: 2022-04-09 02:50:01.800220\n",
      "Epoch [30]: loss: 0.1893748633015688, accuracy: 81%, time finished: 2022-04-09 03:18:32.716867\n",
      "Epoch [31]: loss: 0.17466442175741564, accuracy: 81%, time finished: 2022-04-09 03:47:03.747839\n",
      "Epoch [32]: loss: 0.17870494087350303, accuracy: 81%, time finished: 2022-04-09 04:15:34.673323\n",
      "Epoch [33]: loss: 0.16516605782473148, accuracy: 82%, time finished: 2022-04-09 04:44:04.771555\n",
      "Epoch [34]: loss: 0.17427711492606193, accuracy: 83%, time finished: 2022-04-09 05:12:37.780169\n",
      "Epoch [35]: loss: 0.15666622302085498, accuracy: 80%, time finished: 2022-04-09 05:41:06.865493\n",
      "Epoch [36]: loss: 0.15731782666590374, accuracy: 83%, time finished: 2022-04-09 06:09:36.030366\n",
      "Epoch [37]: loss: 0.1498314725671969, accuracy: 82%, time finished: 2022-04-09 06:38:05.060726\n",
      "Epoch [38]: loss: 0.1510589654729691, accuracy: 83%, time finished: 2022-04-09 07:05:29.054680\n",
      "Epoch [39]: loss: 0.13174967489033726, accuracy: 82%, time finished: 2022-04-09 07:32:55.981580\n",
      "Epoch [40]: loss: 0.13850820465955282, accuracy: 84%, time finished: 2022-04-09 08:00:18.718019\n",
      "Epoch [41]: loss: 0.12893566380138957, accuracy: 83%, time finished: 2022-04-09 08:28:00.913751\n",
      "Epoch [42]: loss: 0.11530132486368934, accuracy: 83%, time finished: 2022-04-09 08:55:46.330257\n",
      "Epoch [43]: loss: 0.11943799291529407, accuracy: 82%, time finished: 2022-04-09 09:23:28.144312\n",
      "Epoch [44]: loss: 0.11758039731505393, accuracy: 82%, time finished: 2022-04-09 09:51:08.654114\n",
      "Epoch [45]: loss: 0.12176784155228848, accuracy: 82%, time finished: 2022-04-09 10:18:48.424661\n",
      "Epoch [46]: loss: 0.11315126547045423, accuracy: 83%, time finished: 2022-04-09 10:46:34.689368\n",
      "Epoch [47]: loss: 0.1057909672367754, accuracy: 81%, time finished: 2022-04-09 11:13:55.413792\n",
      "Epoch [48]: loss: 0.10745972638498742, accuracy: 83%, time finished: 2022-04-09 11:41:04.925047\n",
      "Epoch [49]: loss: 0.10840287073289008, accuracy: 84%, time finished: 2022-04-09 12:08:21.793145\n",
      "Epoch [50]: loss: 0.09678531730165996, accuracy: 82%, time finished: 2022-04-09 12:35:22.753326\n",
      "Epoch [51]: loss: 0.10208740285974628, accuracy: 83%, time finished: 2022-04-09 13:02:23.220798\n",
      "Epoch [52]: loss: 0.09091227606974385, accuracy: 85%, time finished: 2022-04-09 13:29:23.631595\n",
      "Epoch [53]: loss: 0.08570555455139457, accuracy: 83%, time finished: 2022-04-09 13:56:26.200805\n",
      "Epoch [54]: loss: 0.0847970269912973, accuracy: 82%, time finished: 2022-04-09 14:23:51.340790\n",
      "Epoch [55]: loss: 0.0837106650804276, accuracy: 84%, time finished: 2022-04-09 14:50:53.758481\n",
      "Epoch [56]: loss: 0.07908719968186982, accuracy: 83%, time finished: 2022-04-09 15:17:56.646464\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22164/1731207883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#nn.utils.clip_grad_value_(model.parameters(), 0.1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0msched\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "print(\"Training on \", torch.cuda.get_device_name(0))\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,batch in enumerate(trainloader):\n",
    "        \n",
    "        images, targets = batch\n",
    "        loss = model.train_step(images, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        nn.utils.clip_grad_value_(model.parameters(), 0.1)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    sched.step()\n",
    "    acc = calculate_accuracy()\n",
    "    now = datetime.now()\n",
    "\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(f\"Epoch [{epoch}]: loss: {running_loss/len(trainloader)}, accuracy: {acc}%, time finished: {now}\")\n",
    "    running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b2b6a",
   "metadata": {},
   "source": [
    "## Calculate layer output size \n",
    "Output of a conv layer : W-F+ 2xPadding/ stride + 1 <br>W= Input volume e.g 128x128 = 128 <br> F = Filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a71eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width = 150\n",
    "height = 150\n",
    "stride = 3\n",
    "padding = 3\n",
    "filter_size = 3\n",
    "number_of_filters = 32\n",
    "input_channels = 3 #RGB\n",
    "\n",
    "x = torch.zeros([1,input_channels,width,height])\n",
    "conv1 = nn.Conv2d(in_channels = input_channels, out_channels = number_of_filters, kernel_size = filter_size, padding = padding, stride = stride)\n",
    "\n",
    "#x = conv1(x)\n",
    "print(f\"Output width formular = {width} - {filter_size} + 2* {padding} / {stride} + 1 =\", int((width-filter_size + 2 * padding)/stride + 1 ))\n",
    "print(f\"Output height formular = {height} - {filter_size} + 2* {padding} / {stride} + 1 =\", int((height-filter_size + 2 * padding)/stride + 1 ))\n",
    "\n",
    "print(\"Conv output shape: \", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3df741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.zeros([1,input_channels,width,height])\n",
    "\n",
    "network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, padding = 1),\n",
    "            nn.Conv2d(32, 32, 5, padding = 1)\n",
    "            )\n",
    "\n",
    "print(x.shape)\n",
    "print(network(x).shape)\n",
    "\n",
    "network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "    \n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(73984, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy of the network: {100 * correct_images // total_images} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ca8e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_83\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f724969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (res1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res3): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res4): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (res5): Sequential(\n",
      "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (batchnorm2d_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2d_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2d_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2d_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2d_5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2d_6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (classifier): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=8192, out_features=120, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=120, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11eb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
